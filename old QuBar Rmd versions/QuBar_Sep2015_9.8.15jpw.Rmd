---
title: "Attempts at Quantitative Metazoan Metabarcoding are Difficult"
author: "John Wares and Paula Pappalardo"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: pdf_document
bibliography: QuBar_References_Sep2015.bib
---
```{r set working directory,echo=FALSE}
#setwd("~/GitHub/QuBar")
#Paula we must toggle between our different paths to QuBar
setwd("~/Desktop/QuBar")
```
# Abstract (200 words maximum)

__Key words:__(3 to ten)

# Introduction

We start with what may seem like a trivial question: assume that you have been told that a series of fair coin flips resulted in 60% 'heads', 40% 'tails'. This is the only information given, but you already have made a judgment about how many coin flips occurred, and perhaps have generated a probability distribution in your head where the highest likelihood is for 5 or 10, rather than 50 or 100, events. This is taking advantage of what we know about the probability mass function of a binomial distribution, where the observed number of 'successes' in a series is related to the probability of success (here, presumably 50%) and the number of trials.  

Here, we consider whether the same principle could be used for improving the efficiency of exploring the presence, distribution, and abundance of genetic biodiversity. Documenting the distribution and abundance of biodiversity - in many habitats, at multiple scales - is perhaps more important now than ever as scientists evaluate how populations are responding to environmental change. Though technological advances have rapidly improved some elements of this [@Nagendra01; @Bourlat13], there are still glaring deficiencies in our ability to efficiently catalog diversity, even in small domains or limited taxonomic surveys.

The most apparent advances have been in surveys of microbial and viral diversity. Next-generation sequencing has permitted the now-commonplace exploration of fungal, bacterial, and viral diversity by generating $10^5$ - $10^7$ sequence reads per sample and using barcoding approaches (match of sequence to known taxonomic samples for that genomic region) to identify the taxa present and their relative abundance. While there is no doubt that this has transformed our understanding of functional ecosystem processes and microbial ecology at this scale [@Nguyen14; @Turn09; @Desnues08], there are definite limitations. For example, some taxa (e.g. Archaea) may not be as readily amplified using the same ribosomal 16S "bacteria" primers, and variation in amplification efficiency certainly exists within the Eubacteria [@Acinas05]. Additionally, it is known that some bacterial genomes harbor more than one copy of this canonical locus [@Kembel12], thus muddling the relationship between read frequency and taxon frequency in a community.

The same problems exist - and are exacerbated - when studying multicellular diversity. On top of the problems of potential contamination, detecting rare taxa and/or handling singleton evidence for rare taxa, there is potentially a large variance in individual sizes of organisms. This, along with amplification variation given mismatches in the primer region, means that the relative read abundance in a NGS data set will often wildly vary (by multiple orders of magnitude) from the abundance of actual tissue in the data set [@Nguyen14; @Pi?ol14; @Bohmann14]. Researchers tend to address this by analyzing data for simple incidence as well as relative read abundance, to identify patterns robust to either removal of information or inaccurate information [@Nguyen14].

If, however, the goal is to understand the actual relative abundance of individuals of different species in a sample - with these species harboring variation at 'barcode' loci, and often being highly divergent from one another - our question is whether there is complementary information that can be extracted from these data that does not rely on the abundance of reads that are assigned to a taxon, but relies on our understanding of diversity within populations and how that can be measured. 

The summary statistics for DNA sequence diversity are well established and generally recognize the population mutation rate $\theta$ at a given locus; as a population increases in size, or as the mutation rate at that locus increases, more polymorphisms and more diversity will be found. There are limitations to this approach based on Kimura's neutral theory, as various forms of genomic selection will limit the direct relationship between population size and population diversity [e.g., @Bazin06; @Wares10; @Corbett15]. Nevertheless, these summary statistics - including Watterson's $\theta$, a sample-normalized estimator of $\theta$ using the number of segregating sites *S* in a sample - may provide information necessary to generate *some* information about abundance patterns from NGS data. This information also certainly has its limits: nucleotide diversity ($\pi$) requires information on polymorphic site frequencies that will be biased by differential amplification across individuals, as well as relatively uninformative - or diminishing returns - as the number of sampled individuals increases [@Wakeley08]. Haplotype diversity (*H*) is likely sufficient to set a minimum boundary on the number of individuals sampled, and *H* along with *S* may carry enough information to generate a probabilistic distribution associated with  larger numbers of individuals.

Here we present the mathematical considerations necessary to develop these quantitative tools to estimate the relative abundance of species in a barcoding sample of unknown individuals. The tools combine previous information on genetic diversity in the field population with observed properties of the sample, such as the number of haplotypes and the number of segregating sites for each species. We then evaluate the situations in which there is sufficient power to make meaningful statements about relative abundance from polymorphism data alone. 

# Methods

```{r basic params, echo=FALSE,warning=FALSE,results='hide',message=FALSE,fig.show='asis'}

# you may have biomass and/or estimate number indivs, e.g. could see ~200 zooplankton in a sample
# put 20, 200, 2000 indivs on NGS to barcode will not change proportion of reads, just changes depths of coverage
# but this info constrains the posterior in units of individuals rather than proportions
# especially if there are multiple taxa, in which the minimum number of each can be subtracted to set upper boundaries

maxindivs=200
```

The approach here is identifying information that can comfortably be used as prior information to establish the posterior probability of observing polymorphism data from an *unknown* number of input individuals for a taxon. Any type of sampling information may help to set an upper limit: for example, if it is known that only `r maxindivs` individual specimens were originally used for isolation of DNA, then the maximum number of total individuals inferred from this approach should be `r maxindivs`. This itself is not a numerical advance in biology, but limits our prior belief nonetheless.

```{r hapdiv, echo=FALSE,warning=FALSE,results='hide',message=FALSE,fig.show='asis'}

####################################
numhaps=10
Hapdiv=0.7 #minvalue 0.001 if no information; this is PRIOR information
####################################

library(plot3D)

x=1
cdf=0
indprob=0
array<-NULL
while (cdf<0.95) {
  cdfprev<-cdf
#  cdf<-pgamma(x,1,Hapdiv) 
#  if use 1 as shape parameter keeping shape parameter constant doesn't account for increased variance (?) as numhaps go up, 
#  e.g. error may be higher as you observe more...once it is working run it by somebody mathier.
  cdf<-pgamma(x,shape=(1/Hapdiv),rate=(1/numhaps)) #might be that numhaps is actually the shape parameter!!!! or: something else...non-gamma.
  indprob<-cdf-cdfprev
  
  happrob<-numhaps+(x-1)
  array<-c(array,happrob)
  array<-c(array,cdf)
  array<-c(array,indprob)
#  print(happrob)
#  print(cdf)
  x=x+1
}

#par(mfrow=c(3,1))



probs<-t(matrix(array,nrow=3))
probs
#plot(probs[,1],probs[,3],col='red')
maxhaps<-max(probs[,1])

hist3D(x=seq(0,1,length.out=nrow(probs)),y=seq(0,1,length.out=ncol(probs)), probs, border="black",theta=30, phi=50, xlab="h", ylab="n", zlab="P{h}",alpha=0.35)
```

```{r}
#PSKv[k,n]<-PSKv[k,n]+PSK
# this is orphaned now? won't knit for me? so commented out...
```



There are also clear minimum bounds that can be established for the abundance of a taxon. Considering DNA sequence haplotypes as our most basic information, we ask how many *distinct* haplotypes are recovered in the data that match a particular taxon? For a haploid mitochondrial marker like the oft-applied cytochrome oxidase I (COI), this number is the minimum number of individuals present (if the number happens to be zero, it is also likely to be the maximum number of individuals in the sample!). 

We suggest three methods that could help to estimate the number of individuals for a particular species in a metabarcoding sample: 1) an inference based on haplotype diversity of the field population and the observed *number of haplotypes* in the sample, 2) an inference based on the expectations of Ewens'sampling theory and the *number of haplotypes* observed in the sample; and 3) an inference based on a prior assumption of $\theta$ in the field population and the observed *number of segregating sites* in the sample . 

To evaluate the potential usefulness of each method for recovering the abundance of input individuals, we simulated populations evolving under a Wright-Fisher neutral model. We performed the simulations with Hudson's *ms* program [@Hudson2002] using the *gap* [@gap2015] package in R [@RCoreTeam2015]. We simulated 3 populations, using three different population mutation rates ($\theta$ of 2, 10, and 20). For each population we then calculated summary statistics using the *PopGenome* [@PopGenome2014] package in R.

From the simulated populations we took "field samples" of different sizes (n), sampling without replacement. We replicate the sampling experiment 100 times, to be able to assess variation of sampling. For each replicate, we calculate the number of haplotypes and the number of segregating sites, which represent our observed values in the simulated samples. The sampling size, known to us from this design, is what we are going to predict using the reversed inferences described below for each method. All the analysis of the simulated populations was done in R [@RCoreTeam2015]. Detailed information and the R code used to performed simulations is presented in the Appendix S1 in the Supplementary Material.

## Haplotype Diversity

In addition to the simple number of haplotypes observed at a barcode marker, we may also attempt to estimate the number of individuals that harbored those haplotypes. Here, we assume that there is previous information on haplotype diversity (*H*) from the natural populations of the species (or distinguishable populations) that are present in the barcoding sample. The "haplotype diversity", *H*, defined by Nei and Tajima (1981) as $$ H = \frac{N}{N-1}(1-\sum\limits_{i=1}x_{i}^2) $$ represents the probability that sampling a new individual will result in observation of a new haplotype. N is the number of haplotypes, and *x*~i~ is the sample frequency of the i~th~ haplotype.

An example of how *H* could be used is shown below for a sample in which `r numhaps` distinct haplotypes are observed,  and the *prior information about H* for a particular taxon is *H* = `r Hapdiv`. In addition to assuming that prior information about the population is appropriately comparable, here we assume a minimum of `r numhaps` individuals, and that what we do not know can be modeled by a Gamma distribution with the shape defined by the reciprocal of haplotype diversity (so that low diversity provides little information, high diversity suggests that the number of individuals is closer to the observed number of haplotypes), and the rate is defined by the reciprocal of the number of haplotypes.

```{r fig1, echo=FALSE,warning=FALSE,results='hide',message=FALSE,fig.show='asis'}
plot(probs[,1],probs[,3],col='red',pch=19,xlab="Number of individuals (n)",ylab="Probability distribution of n")
```
**Figure 1.** Probability distribution of observing *n* individuals in a sample in which 10 haplotypes are observed, and the haplotype diversity of the field population is *H* = 0.7.

So, observing `r numhaps` haplotypes for this taxon, and given a relatively haphazard use of the Gamma to obtain a useful probability shape given assumptions about how informative haplotype diversity is, we might feel comfortable believing (with a 95% interval) there are between `r numhaps` and `r maxhaps` actual individuals that were sampled, with a highest likelihood solution of **[14 CHECK THIS DID YOU FIGURE OUT BETTER WAY FOR 95%?]**. A concern here lies in the willful abuse of the Gamma distribution without a better understanding of how haplotype diversity *H* and the sample size *N* may be actually related through the frequency of haplotypes - remember, at this point we are assuming we cannot trust the proportion/frequency representation of an allele in our sample.

For each of the 100 replicates in each sampling size within the three simulated populations we used the corresponding haplotype diversity for that population and the number of haplotypes observed in that replicate to estimate the probability distribution of the sampling size using a gamma function as defined above (shape defined by the reciprocal of haplotype diversity and the rate defined by the reciprocal of the number of haplotypes). From each probability distribution we recorded the sampling size with the highest probability (and the confidence intervals) to compare with the experimental/simulated sampling sizes. Finally, we calculated the difference between the "real" sampling size -the one from our simulations- and the sampling size for the sample estimated using the gamma distribution method, as a measure of the precision of our method. 

## Sampling theory 

Ewens [-@Ewens1972] developed a sampling theory of selectively neutral alleles, that based in the number of samples and the mutation parameter $\theta$, allows one to estimate the expected number of different alleles (here, we address alleles from a haploid genome, i.e. haplotypes) in a sample. Assuming a sample of n individuals, the mean number of haplotypes in a sample can be approximated by:

$$ E(h) = \frac{\theta}{\theta}+\frac{\theta}{\theta+1}+...+\frac{\theta}{\theta+n-1} $$

where,
*h* is the number of different haplotypes in the sample,
*n* is the number of individuals in the sample, and
$\theta$: 4N~e~u

If $\theta$ is very small, the expected number of haplotypes should be quite low. On the other hand, if $\theta$ is extremely large, the number of haplotypes should tend to *n* as noted above; of course there is a close relationship between Ewens' sampling theory and our understanding of *H*. Using this equation, we can estimate the distribution of the number of haplotypes for different sampling sizes, with a variance:

$$ Var(h)= E(h)-[\frac{\theta^2}{\theta^2}+\frac{\theta^2}{(\theta+1)^2}+...+\frac{\theta^2}{(\theta+2n-1)^2}] $$

In general, the variance increases with $\theta$ for *n* of biological interest. Ewens' [-@Ewens1972] derivations rely on the assumption that the sample size is much lower than the actual population size. Considering this approach, rather than one based in haplotype diversity *H*, may allow us to avoid the problem of uncertain haplotype frequencies in an empirical data set.

For each of the three populations with theta equal to 2, 10 or 20, and through the range of sampling sizes considered in this study (2 to 128) we applied Ewens [-@Ewens1972] formula to estimate the expected number of haplotypes (and the variance) for each sampling size. We then compared the observed number of haplotypes in each sample with the expected number of haplotypes by Ewens's formula for each sampling size and estimated the "observed" sampling size in our sample. The accuracy of the method was calculated as the difference between the "real" sampling size - the one from our simulations - and the number of individuals for the sample estimated using Ewens's method.

## Segregating Sites

Under the standard coalescent model there are specific probability distributions associated with a sample of sequences, the number of segregating sites *S*, and a prior assumption of $\theta$ [@Wakeley08]:

$$ P(S=k) = \sum\limits_{i=2}^{n}(-1)^i{n-1 \choose i-1}\frac{i-1}{\theta+i-1}(\frac{\theta}{\theta+i-1})^k $$

Figure 2a illustrates this distribution for $\theta$=2, segregating sites *k* from 1 to 20, and number of individuals *n* from 1 to 20. This represents a low-diversity population, and unless few segregating sites are observed there may be a broad range of sample sizes consistent with such an observation. Figure 2b illustrates the same probability distribution, but assuming $\theta$=10, with a range of both *k* and *n* from 1 to 50. When the prior knowledge or assumption of diversity is higher, the range of segregating sites that could give a more accurate inference of *n* is higher, with a sharper distribution on *n* for lower to intermediate *k*.(__JOHN, I rephrased this since what you were seeing was because your plot was using the same set up that theta=2, that is you were not covering the real range of seg sites that you will find with at theta=10, so I updated your plots, but now for higher k the same happen, the possible n's flatten and it is hard to discern between them. If __

```{r WakeleyCh4, echo=FALSE,warning=FALSE,results='hide',message=FALSE,fig.show='asis'}

#install.packages("plot3D")
library(plot3D)

# ------theta = 2-------------
Q = 2 # this is PRIOR information from what you know of input SPECIES, not that particular data set (N. scab Q about 10)
maxn = 20 #above 70 this behaves funny???? OR IT MAY BE SOME MULTIPLE OF Q*maxn that is problem?

obsvdk = 4
maxk = 20 #must be greater than obsvdk

a <- c(1:maxn)
b <- c(1:maxk)
PSKv <- numeric(maxn*maxk)
PSKv <- matrix(PSKv,ncol=maxn)
colnames(PSKv)<-a
rownames(PSKv)<-b

for (n in 2:maxn) {
#  print ("n")
#  print (n)
  for (k in 0:maxk) {
#    print (k)
    PSK=0
    for (i in 2:n) {
#      print (i)
      PSK<-PSK + ((-1)^i)*(choose((n-1),(i-1)))*((i-1)/(Q+i-1))*(Q/(Q+i-1))^k
      
    }
#    print (PSK)
    PSKv[k,n]<-PSKv[k,n]+PSK
    obsvd<-PSKv[obsvdk,]

  }
  
}

# ------theta = 10-------------
Q=10

maxn = 50 
obsvdk = 4
maxk = 50 #must be greater than obsvdk


a2 <- c(1:maxn)
b2 <- c(1:maxk)
PSKv2 <- numeric(maxn*maxk)
PSKv2 <- matrix(PSKv2,ncol=maxn)
colnames(PSKv)<-a2
rownames(PSKv)<-b2

for (n in 2:maxn) {

  for (k in 0:maxk) {

    PSK2=0
    for (i in 2:n) {

      PSK2<-PSK2 + ((-1)^i)*(choose((n-1),(i-1)))*((i-1)/(Q+i-1))*(Q/(Q+i-1))^k
      
    }

    PSKv2[k,n]<-PSKv2[k,n]+PSK2


  }
  
}

#par(mfrow=c(2,1))

# ----make Wakeley plots--------
# NOTE: the "theta" command in the hist3D function is to define view angles and it is not related to the theta defined by us as mutation rate #

hist3D(x=seq(0,1,length.out=nrow(PSKv)), y=seq(0,1,length.out=ncol(PSKv)), PSKv, col=NULL, border="black", theta=30,  phi=50,       xlab="k", ylab="n", zlab="P{S=k}", alpha=0.35)

hist3D(x=seq(0,1,length.out=nrow(PSKv2)),y=seq(0,1,length.out=ncol(PSKv2)),PSKv2,col=NULL,border="black",theta=30,phi=50,xlab="k",ylab="n",zlab="P{S=k}",alpha=0.35)

#par(mfrow=c(1,1))

```

**Figure 2.** Probability surface of observing a number of segregating sites *k* for a given sample size *n* when $\theta$ is set. In (a), $\theta$ = 2; in (b), $\theta$ = 10.

For each of the three populations with theta equal to 2, 10 or 20, and with a range of sampling sizes from 1 to 50, we applied Ewens [-@Ewens1972] formula to estimate the expected number of haplotypes (and the variance) for each sampling size. We tried higher samping sizes but our computation of Ewens's formula failed for sampling sizes larger than 60 and exhibit a weird behaviour. 
We then compared the observed number of segregating sites in each sample with the expected number of segregating sites expected using Wakeley's formula for each sampling size and estimated the "observed" sampling size in our sample. The accuracy of the method was calculated as the difference between the "real" sampling size - the one from our simulations - and the number of individuals for the sample estimated using Wakeley's method.

# Results 

The summary statistics of the simulated population data are presented in Table 1, the R code used to performed the simulations and estimate the summary statistics is presented in Appendix S1. As expected, the haplotype diversity, number of haplotypes and number of segregating sites are higher as $\theta$ increases. [**hmmm yes that value of D for population 6 is strange; plus we should rename populations since there are now only 3**]

```{r Table 1 with info on simulated populations, warnings=F,message=FALSE, echo=FALSE,results='hide'}
#install.packages("gap")
#install.packages("knitr")

library(gap)
library(PopGenome)
library(knitr)

# reading the simulated populations files with PopGenome----
#readMS("theta2Growth.out")->popgen.t2g #gives a "genome" object
readMS("theta2NoGrowth.out")->popgen.t2ng
#readMS("theta10Growth.out")->popgen.t10g
readMS("theta10NoGrowth.out")->popgen.t10ng
#readMS("theta20Growth.out")->popgen.t20g
readMS("theta20NoGrowth.out")->popgen.t20ng

# number of segregating sites----
#varsites.t2g<-popgen.t2g@n.biallelic.sites
varsites.t2ng<-popgen.t2ng@n.biallelic.sites
#varsites.t10g<-popgen.t10g@n.biallelic.sites
varsites.t10ng<-popgen.t10ng@n.biallelic.sites
#varsites.t20g<-popgen.t20g@n.biallelic.sites
varsites.t20ng<-popgen.t20ng@n.biallelic.sites
varsites<-c(varsites.t2ng,varsites.t10ng,varsites.t20ng)

# run F_ST stats and check haplotype diversity
#F_ST.stats(popgen.t2g)->popgen.t2g
F_ST.stats(popgen.t2ng)->popgen.t2ng
#F_ST.stats(popgen.t10g)->popgen.t10g
F_ST.stats(popgen.t10ng)->popgen.t10ng
#F_ST.stats(popgen.t20g)->popgen.t20g
F_ST.stats(popgen.t20ng)->popgen.t20ng

# get haplotype diversity for each source population----
#unlist(popgen.t2g@region.stats@haplotype.diversity)->hapDiv.t2g
unlist(popgen.t2ng@region.stats@haplotype.diversity)->hapDiv.t2ng
#unlist(popgen.t10g@region.stats@haplotype.diversity)->hapDiv.t10g
unlist(popgen.t10ng@region.stats@haplotype.diversity)->hapDiv.t10ng
#unlist(popgen.t20g@region.stats@haplotype.diversity)->hapDiv.t20g
unlist(popgen.t20ng@region.stats@haplotype.diversity)->hapDiv.t20ng
hapDiv<-c(hapDiv.t2ng,hapDiv.t10ng,hapDiv.t20ng)

# get haplotype counts----
#length(unlist(popgen.t2g@region.stats@haplotype.counts)/1000)->hapCount.t2g
length(unlist(popgen.t2ng@region.stats@haplotype.counts)/1000)->hapCount.t2ng
#length(unlist(popgen.t10g@region.stats@haplotype.counts)/1000)->hapCount.t10g
length(unlist(popgen.t10ng@region.stats@haplotype.counts)/1000)->hapCount.t10ng
#length(unlist(popgen.t20g@region.stats@haplotype.counts)/1000)->hapCount.t20g
length(unlist(popgen.t20ng@region.stats@haplotype.counts)/1000)->hapCount.t20ng
hapcounts<-c(hapCount.t2ng,hapCount.t10ng,hapCount.t20ng)

# run neutrality.stats to check that Tajima's D is negative and looks real----
#neutrality.stats(popgen.t2g)->popgen.t2g
neutrality.stats(popgen.t2ng)->popgen.t2ng
#neutrality.stats(popgen.t10g)->popgen.t10g
neutrality.stats(popgen.t10ng)->popgen.t10ng
#neutrality.stats(popgen.t20g)->popgen.t20g
neutrality.stats(popgen.t20ng)->popgen.t20ng

#Taj.t2g<-popgen.t10g@Tajima.D
Taj.t2ng<-popgen.t10ng@Tajima.D
#Taj.t10g<-popgen.t10g@Tajima.D
Taj.t10ng<-popgen.t10ng@Tajima.D
#Taj.t20g<-popgen.t20g@Tajima.D
Taj.t20ng<-popgen.t20ng@Tajima.D
tajima<-c(Taj.t2ng,Taj.t10ng,Taj.t20ng)

# summary table
thetas<-c(2,10,20)
pops<-c("Population 1","Population 2","Population 3")
#growth<-c("yes","no","yes","no","yes","no")
newhap<-round(hapDiv,2)
newtaj<-round(tajima,2)
sumTable<-cbind(pops,thetas,newhap,newtaj,hapcounts,varsites)
colnames(sumTable)<-c("Population","Theta","Haplotype diversity","Tajima's D","Number of haplotypes","Number of segregating sites")

```

**Table 1**. Summary information on the simulated "field" populations that were used in this study.

```{r show table,echo=FALSE}
library(knitr)
kable(sumTable)
```

## Haplotype diversity and gamma estimation

Overall, using haplotype diversity and our educated guess at how this diversity reflects the input tends to greatly underestimate the simulated sample, at least for larger sampling size (Figure 3). For the smaller sampling sizes the difference between the predicted sampling size and the simulated sampling size is close to zero, meaning the method provides little error; the difference is also smaller when $\theta$ is larger (Figure 3). 

The probability distributions using this method and the predicted sampling sizes against the observed haplotypes are provided in the supplementary material. 

```{r figure 3,message=FALSE, echo=FALSE}
library(ggplot2)

# loading data
fullgammaData <- read.csv("gammaData_13Jul.csv",header=T) 

# subsetting data with growth
gammaData <- subset(fullgammaData,fullgammaData$Growth=="no")
droplevels(gammaData) -> gammaData

# calculating the difference between "real" n and max gamma.
gammaData$samplingSize-gammaData$Max.Gamma.value -> gammaData$dif

# Figure 3
ggplot(gammaData, aes(x=samplingSize, y=dif,color=Theta))+ theme_bw() + geom_point(position = "jitter", aes(alpha=0.7))+ geom_hline(yintercept = 0) + scale_alpha(guide = 'none')
```
**Figure 3.** Difference between the simulated sampling size and the sampling size for the sample predicted using the gamma distribution method. The abline at zero shows the ideal situation with the estimation equal to the simulated sampling size.

## Sampling theory

Using Ewens's sampling theory and backcalculating the sampling size from the number of haplotypes gives a difference between the simulated and predicted sampling size that is centered to zero. The efficacy of this method (the difference between observed and predicted sampling size) decreases with an increase in sampling size and increases when the original population has a larger theta (from two to twenty). 

```{r sampling theory, echo=FALSE,message=FALSE}
library(ggplot2)

# -----observed data------
# ------------------------
# load data of number of haplotypes
hapdata <- read.csv("numberHaplotypes.csv",header=T)

# subsetting data with growth
minidata <- subset(hapdata,hapdata$Growth == "no")
minidata[,-1] -> minidata
droplevels(minidata) -> minidata
row.names(minidata) <- NULL # cleaning row.names
#View(minidata)

# creating and id to merge later
myObMatrix <- as.matrix(minidata[,c("Theta","n.haplotypes")])
minidata$id <- apply(myObMatrix, 1, paste, collapse=" ")

# -----predicted data------
#--------------------------
# load data of Ewens sampling theory
theory <- read.csv("dataSamplingTheory_21Ago2015.csv",header=T)

# round the expected number of haplotypes
round(theory$exp.haplotypes,0) -> theory$exp.round.hap

# create id to merge
myPredMatrix <- as.matrix(theory[,c("theta.df","exp.round.hap")])
theory$id <- apply(myPredMatrix, 1, paste, collapse=" ")
#View(theory)

#---- merge predicted with observed data-----
newdata <- merge(theory,minidata,by="id",all.y=T)
#newdata[is.na(newdata$n.df),] # check NA's
newdata[complete.cases(newdata),]->newdata1

# calculate difference between Ewens n and the simulated n
newdata1$samplingSize-newdata1$n.df -> newdata1$difEwens

# check weird stuff
#View(subset(newdata1,newdata1$Theta=='two'))

ggplot(newdata1, aes(x=samplingSize, y=difEwens,color=Theta,alpha=0.5)) + theme_bw()+geom_point()+geom_point(position = "jitter")+geom_hline(yintercept=0)+facet_grid(Theta~.)+theme(legend.key = element_blank())

```

**Figure 4.** Difference between the simulated sampling size and the sampling size for the sample predicted using Ewens's sampling theory. The abline at zero shows the ideal situation in which the estimation equals the simulated sampling size. The panels separate the three different theta: two, ten and twenty.

## Theta and segregating sites approach

The implementation of Wakeley's [-@Wakeley08] formula for estimation of the relationship between *S*, *n*, and $\theta$ was tested for sample sizes up to 50; instabilities in estimation at large samples limited our ability to explore larger samples, but instead we focused on the full range of each sample size from 2-50.


```{r plotting Wakeley data NEW DATA,echo=FALSE,message=FALSE,warning=FALSE}
library(ggplot2)
library(lattice)
library(plyr)
library(modeest)

# we have two types of data:
# "WakeleyData"" has the result of Wakeley formula with all the possible vlues and distributions
# "segsites" has the observed number of seg.sites in the simulations
wakdata<-read.csv("WakeleyData_01Sep2015.csv",header=T)
segsites<-read.csv("numberSegSites_31Ago2015.csv",header=T)

# making factors for the ggplot2 plots
factor(wakdata$wak.segsites)->wakdata$wak.segsites.f
factor(segsites$samplingSize)->segsites$samplingSize.f

# -----------------------------------
# ------observed segsites------------
# -----------------------------------
segsites[,-1] -> segsites
segsites$Pop <- NULL
segsites$Growth <- NULL

# estimate the mode (the more frequent value) for each combination of sampling size and theta
# the mode is estimated with the function mvl in the package "modeest"
# the warning is because there are multiple modes and I'm collapsing them with the "unlist"
modes <- ddply(segsites, c("Theta","samplingSize.f"), summarise, mode=unlist((mlv(n.seg.sites))[1]))
modes$samplingSize <- as.numeric(as.character(modes$samplingSize.f))

# -------------------------------------
# -------Wakeley's predictions --------
# -------------------------------------

# estimate the best n's of wakeley data
bestprobs <- ddply(wakdata, c("Theta","wak.segsites.f"), summarise, best.prob=max(wak.prob))
bestprobs$best.prob <-round(bestprobs$best.prob,13)

# merging "bestprobs" with "wakdata" to recover the n's that match with the higher probability
best.n <- merge(bestprobs,wakdata,by.x=c("Theta","wak.segsites.f","best.prob"),by.y=c("Theta","wak.segsites.f","wak.prob"),all.x=T)


# Now we want to merge the observed segregating sites with the segregating sites used to estimate Wakeley's formula, and that will allow us to plot the "real" n vs the best.n according Wakeley.
allwak <-merge(modes,best.n,by.x=c("Theta","mode"),by.y=c("Theta","wak.segsites"))

# Calculate difference between real and predicted n
allwak$dif <- allwak$samplingSize - allwak$wak.n

ggplot(allwak, aes(x=samplingSize, y=dif,color=Theta)) + theme_bw()+geom_point()+geom_point(position = "jitter")+geom_hline(yintercept=0)

```




# Discussion

What we have shown is, in effect, the high variance in genealogical and mutational data associated with the coalescent process in population genetics [@Kingman82]. Though our early efforts suggested a broad utility in ranking the abundance of taxa in a mixed sample of metabarcode data, the result of our extended simulations indicate a preponderance of high-variance, downward-biased results in estimating the number of individuals in a sequence data set. In considering basic haplotype diversity *H*, the observed number of haplotypes, as well as the number of segregating sites *S*, our attempts to use genetic diversity tend to greatly underestimate the simulated sample of individuals, at least for larger sampling sizes and/or low values of $\theta$. If the goal is to improve our ability to quantitatively describe the biodiversity in a system using metabarcoding approaches, we show that such an approach is of poor utility unless the diversity of the system is high and the number of individuals input to the metabarcoding analysis is modest. Given the additional uncertainty associated with assumptions of comparable diversity from prior evaluation of each population, there are no benefits in cost or estimation over traditional barcoding of individual specimens.

The statistics we evaluate are not independent from one another; they pertain to the same genealogical process assumed to underlie a sample of DNA sequence data and are different ways of summarizing this coalescent process. Although some methods, e.g. approximate Bayesian computation, have been used to infer the demographic history of a sample of sequences using the aggregate of summary statistics available (e.g. Ilves et al. 2010), the relationship shown here appears to be too tenuous to make an advance in our ability to estimate relative abundance of taxa from such metabarcode data. Some of the error or bias in estimation we note from our simulation work reflects common problems in sampling data and exploring them with summary statistics. Felsenstein [-@Felsenstein92] had noted that a high variance (in fact, driven by bimodal distribution of resultant statistics) in the number of segregating sites *S* would be expected with low sample size. Effectively, the comparison of a small number of sequences in a high-diversity system has a large probability of pairwise contrasts across the oldest node of a genealogy [@Felsenstein92], and at very small sample sizes there is a potential that two closely-related sequences are sampled rather than reflect the TMRCA of the genealogy.

Additionally, our approach is predicated on the idea that prior analysis of a given population - a genetically discrete and relatively homogeneous evolutionary unit - will effectively suggest the diversity to be found in subsequent samples. There are certainly instances where the diversity at a barcode locus has been so extraordinarily high that haplotype diversity approached 1, and the number of haplotypes recovered in a sample was very close to the number of individuals in that sample, such as the barnacle *Balanus glandula* [@Wares01,@Sotka04,@Wares05]. However, this same example of a hyperdiverse barnacle also requires recognition that there are at least 2 distinct evolutionary lineages in this taxon with broadly overlapping geographic ranges [@Sotka04,@Wares05], which dramatically affects our understanding of the diversity recovered as well as the underlying genealogical process and association with regional diversity.

This leaves metabarcode research with three options: (1) continue to individually sequence using Sanger methods; (2) only use metabarcode data for presence/absence of a taxon; (3) in cases where the amplification bias may be considered negligible, as with closely-related lineages, the frequency of reads may be useful for approximating the *relative* but not absolute abundance of lineages in a sample. It should be noted that the problem we face - unknown input to the diversity observed - is a similar problem that biologists have handled studying species introductions (Wares et al. 2005), now exacerbated by the confounding issues of next-generation sequencing and differential PCR success.

Though there are concerns about how well read/sequence frequency reflects the relative abundance of populations in an environmental sample - driven largely by differential amplification success of target genomes [@Nguyen14; @Pinol14; @Bohmann14], it is worth noting that among high-$\theta$ populations there may still be comparisons appropriate in a relative sense: greater haplotypic diversity from a metabarcode sample would suggest more individuals of that species were in the sample. In this way we can evaluate order-of-magnitude results, and have less need for prior information from a population. As a complementary recognition that the number of haplotypes provides us with more information than simple presence/absence, we may start to improve on our ability to recover actual ecology from actual molecules.



# Acknowledgments

Idea brought about by extended problem-solving session with J. Drake and colleagues in the Odum School of Ecology and Department of Genetics at The University of Georgia (UGA). Our work was improved greatly by suggestions from C. Ewers-Saucedo and K. Bockrath. This work was supported by funding from NSF (OCE-1029526) and the UGA Department of Genetics.

# Figure captions


# Supporting information 

__Appendix S1.__R code used to perform simulations and to estimate genetic diversity indexes. *NOTE: we need to finish the edits to this appendix, it is just a start*

```{r Supp Fig 1 gamma distribution plots,message=FALSE, echo=FALSE}
setwd("~/GitHub/QuBar")

#install.packages("ggplot2")
library(ggplot2)

# now we have the dataframe "gammaData_13jul" with all the updated gamma values 
fullgammaData<-read.csv("gammaData_13Jul.csv",header=T) 
#JOHN: this one is the updated file after your new twist on gamma, I deleted the other one

# subsetting data with growth
gammaData<-subset(fullgammaData,fullgammaData$Growth=="no")
droplevels(gammaData)->gammaData

# making factors for the ggplot2 plots
factor(gammaData$samplingSize,levels=c(2,4,8,16,32,64,128))->gammaData$samplingSizeF

# subsetting small sampling sizes to see better what happen there
#minigamma<-gammaData[gammaData$samplingSize<33,]

# plotting with ggplot, need to fix legends
#http://www.cookbook-r.com/Graphs/Legends_(ggplot2)/
# Fig X2a
#ggplot(gammaData, aes(x = samplingSize,y=Max.Gamma.value,fill=Theta,color=Theta)) + theme_bw()+geom_point()+geom_abline()+xlab("simulated sampling size") + ylab("predicted sampling size") 

# Fig X2b
# thinking how to plot the subset of samples sizes where gamma works a little bit better....
#ggplot(minigamma, aes(x = samplingSizeF,y=Max.Gamma.value,fill=Theta,color=Theta)) + theme_bw()+ geom_boxplot(aes(fill=Theta)) + ylim(0,20) + xlab("simulated sampling size") + ylab("predicted sampling size")

#JOHN, trying something different below
fig3<-ggplot(gammaData, aes(x = n.haplotypes,y=Max.Gamma.value,color=samplingSizeF,size=1)) + theme_bw()+geom_point()+facet_grid(Theta~samplingSizeF) 
fig3 + geom_hline(aes(yintercept = 2), subset(gammaData,samplingSize==2))+ geom_hline(aes(yintercept = 4), subset(gammaData,samplingSize==4))+ geom_hline(aes(yintercept = 8), subset(gammaData,samplingSize==8))+ geom_hline(aes(yintercept = 16), subset(gammaData,samplingSize==16))+ geom_hline(aes(yintercept = 32), subset(gammaData,samplingSize==32))+ geom_hline(aes(yintercept = 64), subset(gammaData,samplingSize==64))+ geom_hline(aes(yintercept = 128), subset(gammaData,samplingSize==128))+theme(panel.grid.major = element_blank())

# to put different ablines in different facets we need to make a dataset, and this would be efficient but the order is all messed up so I had to figure out a not so efficient but working way ;)
#hline.data <- data.frame(z = c(2,4,8,16,32,64,128),samplingSizeF = c(2,4,8,16,32,64,128))
#fig3 + geom_hline(aes(yintercept = z), hline.data)
                                                                                                                                                                                  
```

**Supplementary Figure 1.** Predictions of sampling size using the gamma distribution method for each population (with thetas 2,10 and 20) against the observed number of haplotypes in the sample. The ablines in each panel represent the "real" sampling size of that sample.  

# Literature Cited


