---
title: "Doing Simulations"
author: "Paula Pappalardo"
date: "Wednesday, April 22, 2015"
output: pdf_document
---

# Running simulations

After the first trials, I realized the best method is to call "ms" from R, read that from *gap* and save the file to read it also with *PopGenome*. With *gap* we are able to estimate number of haplotypes. With *PopGenome* we are able to estimate haplotype diversity and also Tajima's D for the cases that we want to simulate "real" populations.

We are going to simulate four populations of 1000 individuals, with the following parameters:

1) theta=2, growth rate to have "good" Tajima's D
2) theta=10, growth rate to have "good" Tajima's D
3) theta=2, no growth
4) theta=10, no growth.

For these four populations we are going to calculate the haplotype diversity and the Tajima's D (to check).

From each of the four populations we are going to sample without replacement "field samples" of 2,4,8,16,32,64 and 128 individuals. That way we know the real n. Using the number of haplotypes and the number of segregating sites of the "field samples" we are going to do our best to back calculate the number of individuals in that sample, using as prior information the haplotype diversity of the original population (n=1000).

The only thing that we need to keep from each "field sample" is the number of haplotypes and number of segregating sites. So to save memory I may try to clean the files we are not using if things get problematic...

NOTE: one thing to have in mind is that we are not controlling for sequence length since there are no sequences in the ms output and we are just seing the segregating sites. That's why the sequence length that is usually visibly with the summary stats in PopGenome is zero when we are reading the ms output file. It shouldn't matter for the things we discussed.

Let's do it! :)

```{r simulating source populations}
library(gap)
library(PopGenome)

# -----gap----
# we can call ms from R without having to use the console and read the object directly with the gap function

# with -G x we set a population growth, a negative value of x means that the population was larger in the past that at present. 

# Simulating our source populations
theta2Growth <- system("ms 1000 1 -t 2 -G 10", intern=TRUE)
theta2NoGrowth <- system("ms 1000 1 -t 2", intern=TRUE)
theta10Growth <- system("ms 1000 1 -t 10 -G 10", intern=TRUE)
theta10NoGrowth <- system("ms 1000 1 -t 10", intern=TRUE)

# we need to write the outputs so we can read them using PopGenome
#write(theta2Growth,"theta2Growth.out")
#write(theta2NoGrowth,"theta2NoGrowth.out")
#write(theta10Growth,"theta10Growth.out")
#write(theta10NoGrowth,"theta10NoGrowth.out")

# reading with PopGenome to calculate H and Tajima's D for each of the four populations
readMS("theta2Growth.out")->popgen.t2g #gives a "genome" object
readMS("theta2NoGrowth.out")->popgen.t2ng
readMS("theta10Growth.out")->popgen.t10g
readMS("theta10NoGrowth.out")->popgen.t10ng

# run F_ST stats and check haplotype diversity
F_ST.stats(popgen.t2g)->popgen.t2g
F_ST.stats(popgen.t2ng)->popgen.t2ng
F_ST.stats(popgen.t10g)->popgen.t10g
F_ST.stats(popgen.t10ng)->popgen.t10ng

# get haplotype diversity for each source population
unlist(popgen.t2g@region.stats@haplotype.diversity)->hapDiv.t2g
unlist(popgen.t2ng@region.stats@haplotype.diversity)->hapDiv.t2ng
unlist(popgen.t10g@region.stats@haplotype.diversity)->hapDiv.t10g
unlist(popgen.t10ng@region.stats@haplotype.diversity)->hapDiv.t10ng

hapDiv<-c(hapDiv.t2g,hapDiv.t2ng,hapDiv.t10g,hapDiv.t10ng)
hapDiv

# run neutrality.stats to check that Tajima's D is negative and looks real
neutrality.stats(popgen.t2g)->popgen.t2g
neutrality.stats(popgen.t2ng)->popgen.t2ng
neutrality.stats(popgen.t10g)->popgen.t10g
neutrality.stats(popgen.t10ng)->popgen.t10ng

Taj.t2g<-popgen.t10g@Tajima.D
Taj.t2ng<-popgen.t10ng@Tajima.D
Taj.t10g<-popgen.t10g@Tajima.D
Taj.t10ng<-popgen.t10ng@Tajima.D

tajima<-c(Taj.t2g,Taj.t2ng,Taj.t10g,Taj.t10ng)
tajima
```

Now that we have our 4 populations and we have H and Tajima's D for those, we need to take our "field samples". For that, we are going to use the same pop generated above and read those with gap. Then, using the matrix of the variables sites for the 1000 individuals we are going to take random samples. We are going to use sample sizes from 2 to 128 in a log2 scale.

# Taking "field samples"

```{r taking field samples}
library(gap)
library(PopGenome)

# reading the ms output generated in the previous chunk with gap
# this way works for reading the object from R, but it is not useful if we want to maintain the origina same populations, because I was not able to make the "seeds" work
#read.ms.output(theta2Growth,FALSE)->pop1
#read.ms.output(theta2NoGrowth,FALSE)->pop2
#read.ms.output(theta10Growth,FALSE)->pop3
#read.ms.output(theta10NoGrowth,FALSE)->pop4

# this way, we read the same files that were simulated only once, and the same that we read with PopGenome
read.ms.output("theta2Growth.out",is.file=T)->pop1
read.ms.output("theta2NoGrowth.out",is.file=T)->pop2
read.ms.output("theta10Growth.out",is.file=T)->pop3
read.ms.output("theta10NoGrowth.out",is.file=T)->pop4

# --------sampling from each population---------
# vector with all the populations for loops or easy coding
pop<-list(pop1,pop2,pop3,pop4)

# vector with the sizes we want to sample
popsizes<-c(2,4,8,16,32,64,128)

# we extract the gametes matrix for each population, from there we take the samples, we put the matrix obtained in each "sample" in a list called "samples", and the result for each population in a list called "populations"

populations<-list()

for(i in 1:length(pop)){
  pop[[i]]->ourpop
  namepop<-paste("popOrigen",i,sep="")
  t(ourpop$gametes[[1]])->mat
  samples<-list()  
    for(j in popsizes){
        name<-paste("sampleSize",j,sep="")
        mat[sample(nrow(mat),size=j,replace=FALSE),]->sampMat
        sampMat->samples[[name]]
      }
  samples->populations[[namepop]]
}  # now in each of the 4 component of the list "populations", we have the 7 lists with the samples corresponding to each of the sampling sizes 

# to sample 100 replicates within each sample size
populations<-list()
for(i in 1:length(pop)){
  pop[[i]]->ourpop
  namepop<-paste("popOrigen",i,sep="")
  t(ourpop$gametes[[1]])->mat
  samples<-list()  
    for(j in popsizes){
        name<-paste("sampleSize",j,sep="")
        replicates<-list()
        for (k in 1:100){
        namerep<-paste("replicate",k,sep="")  
        mat[sample(nrow(mat),size=j,replace=FALSE),]->rep
        rep->replicates[[namerep]]
        }
        replicates->samples[[name]]
      }
  samples->populations[[namepop]]
} # now in each of the 4 components of the list "populations", we have 7 list with each component corresponding to each sample size, and within each of this list we have 100 components corresponding to each replicate of the sampled matrix.
```

Now we are going to calculate number of  haplotypes and number of segregating sites for each of the replicates in each of the samples in each of the 4 populations. The loops takes a while to be able to do it for all the replicates.

```{r calculating haplotypes}
# Now for each sample we need to calculate the segregating sites and number of haplotypes
# the haplotype number can be extracted by doing unique() of the matrix
hapResults<-list()
for(i in 1:length(pop)){
  populations[[i]]->popnow
  namepop<-paste("popOrigen",i,sep="")
  samples<-list()
  for (j in 1:length(popsizes)){
    namesample<-paste("sampleSize",j,sep="")  
    popnow[[j]]->samplenow
    for (k in 1:100){
      sapply(samplenow,function(x) nrow(unique(x)))->result
      unlist(result)->replicates
      }
    replicates->samples[[namesample]]
    }
  samples->hapResults[[namepop]]
} # now hapResults is a list of vectors with the haplotypes number for each population, in each sample size
hapResults[[1]]->pop1haps
hapResults[[2]]->pop2haps
hapResults[[3]]->pop3haps
hapResults[[4]]->pop4haps
```

```{r calculating segregating sites}
# load function to estimate segregating sites, it works taking a matrix of gametes and returning a numeric value, the number of segregating sites.
estimate.segSites <- function(myMatrix){
  answers<-rep(NA,(nrow(myMatrix)-1))
  sites<-rep(NA,ncol(myMatrix))
    for (j in 1:ncol(myMatrix)){
      for (i in 1:(nrow(myMatrix)-1)){
        (myMatrix[i+1,j]==myMatrix[1,j])->answers[i]
      }
      if (all(answers)==TRUE) {0->sites[j]}
      else {1->sites[j]}
      }
    sum(sites,na.rm=T)->segSites
    return(segSites)
  }

# to get segsites for each population we need to use our custome function in a loop
segResults<-list()
for(i in 1:length(pop)){
  populations[[i]]->popnow
  namepop<-paste("popOrigen",i,sep="")
  samples<-list()
  for (j in 1:length(popsizes)){
    namesample<-paste("sampleSize",j,sep="")
    popnow[[j]]->samplenow
    sapply(samplenow,function(x) estimate.segSites(x))->result
    result->samples[[namesample]]
    }
  samples->segResults[[namepop]]
}  # now segResults is a list of 4 lists (one for each population), within each of those list compose of a list of 7 vectors, one for each sample size, and with a length of 100, where each component is the segregating sites for the 100 replicates. 
segResults
segResults[[1]]->pop1segsites
segResults[[2]]->pop2segsites
segResults[[3]]->pop3segsites
segResults[[4]]->pop4segsites
```

# Using the gamma approach

Now we have 100 replicates of each sample size, for each population, and we want to run the gamma stats for each replicate in each sampling size. To save the results I created a dataframe "toFill", and since the haplotype calculation takes its time, I will save that dataframe so we don't have to calculate the haplotypes each time.

```{r gamma distribution code,eval=F}
# load libraries
library(lattice)
library(ggplot2)
library(vioplot)

# Number of samples, from a log2 distribution, it is the same for all populations
numsamp<-c(2,4,8,16,32,64,128) 

# Haplotype diversity for each of the four simulated populations of 1000 individuals
hapdiv<-c(0.5504204, 0.3377538, 0.8915536, 0.9258679)

# Number of haplotypes for each replicates are in a list within a list
# pop1haps (list of 7 sampling sizes, that includes the list with 100 replicates)
# pop2haps
# pop3haps
# pop4haps

# We can make this more efficient, but for now, let's keep a loop for each population:

# set dataframe to fill with the predicted and observed values,for each population, we need 
Population<-rep(NA,700)
Max.Pred.value<-rep(NA,700)
data.frame(Population,Max.Pred.value)->toFill
toFill->toFill2
toFill->toFill3
toFill->toFill4

# Loop in all populations to get the estimates----

# Loop population 1
count<-0
for (j in 1:7){
  pop1haps[[j]]->ourSize
  names(ourSize)<-NULL
    for(i in 1:100){
      x=1
      cdf=0
      indprob=0
      array<-NULL
    while (cdf<0.99) {
      cdfprev<-cdf
      cdf<-pgamma(x,ourSize[i],hapdiv[1]) 
      indprob<-cdf-cdfprev
      happrob<-ourSize[i]+(x-1)
      array<-c(array,happrob)
      array<-c(array,cdf)
      array<-c(array,indprob)
      x=x+1
      }
  probs<-t(matrix(array,nrow=3))
  probs
  max<-max(probs[,3])
  maxPred<-probs[which(probs[,3]==max),1]
  toFill$Max.Pred.value[i+count]<-maxPred
  toFill$Obs.n[i+count]<-numsamp[j]
  toFill$Population[i+count]<-"Pop1"
  }
  count+100->count
 }

# Loop population 2
count<-0
for (j in 1:7){
  pop2haps[[j]]->ourSize
  names(ourSize)<-NULL
    for(i in 1:100){
      x=1
      cdf=0
      indprob=0
      array<-NULL
    while (cdf<0.99) {
      cdfprev<-cdf
      cdf<-pgamma(x,ourSize[i],hapdiv[1]) 
      indprob<-cdf-cdfprev
      happrob<-ourSize[i]+(x-1)
      array<-c(array,happrob)
      array<-c(array,cdf)
      array<-c(array,indprob)
      x=x+1
      }
  probs<-t(matrix(array,nrow=3))
  probs
  max<-max(probs[,3])
  maxPred<-probs[which(probs[,3]==max),1]
  toFill2$Max.Pred.value[i+count]<-maxPred
  toFill2$Obs.n[i+count]<-numsamp[j]
  toFill2$Population[i+count]<-"Pop2"
  }
  count+100->count
 }

# Loop population 3
count<-0
for (j in 1:7){
  pop3haps[[j]]->ourSize
  names(ourSize)<-NULL
    for(i in 1:100){
      x=1
      cdf=0
      indprob=0
      array<-NULL
    while (cdf<0.99) {
      cdfprev<-cdf
      cdf<-pgamma(x,ourSize[i],hapdiv[1]) 
      indprob<-cdf-cdfprev
      happrob<-ourSize[i]+(x-1)
      array<-c(array,happrob)
      array<-c(array,cdf)
      array<-c(array,indprob)
      x=x+1
      }
  probs<-t(matrix(array,nrow=3))
  probs
  max<-max(probs[,3])
  maxPred<-probs[which(probs[,3]==max),1]
  toFill3$Max.Pred.value[i+count]<-maxPred
  toFill3$Obs.n[i+count]<-numsamp[j]
  toFill3$Population[i+count]<-"Pop3"
  }
  count+100->count
 }

# Loop population 4
count<-0
for (j in 1:7){
  pop4haps[[j]]->ourSize
  names(ourSize)<-NULL
    for(i in 1:100){
      x=1
      cdf=0
      indprob=0
      array<-NULL
    while (cdf<0.99) {
      cdfprev<-cdf
      cdf<-pgamma(x,ourSize[i],hapdiv[1]) 
      indprob<-cdf-cdfprev
      happrob<-ourSize[i]+(x-1)
      array<-c(array,happrob)
      array<-c(array,cdf)
      array<-c(array,indprob)
      x=x+1
      }
  probs<-t(matrix(array,nrow=3))
  probs
  max<-max(probs[,3])
  maxPred<-probs[which(probs[,3]==max),1]
  toFill4$Max.Pred.value[i+count]<-maxPred
  toFill4$Obs.n[i+count]<-numsamp[j]
  toFill4$Population[i+count]<-"Pop4"
  }
  count+100->count
 }

# putting populations together
rbind(toFill,toFill2,toFill3,toFill4)->gammaData

# With this I can do a summary table of the frequency of predicted haplotypes for each observed value
table(toFill$Pred.value,toFill$Obs.n)

# save result so we don't need to rerun----
write.csv(gammaData,"gammaData.csv")
```

```{r gamma distribution plot}
# now we have the dataframe "gammaData" with all the values we need to plot
gammaData<-read.csv("gammaData.csv",header=T)

par(mfrow=c(1,1))
plot(Pred.value~Obs.n,data=toFill)
vioplot(toFill$Pred.value,add=T,horizontal=F,lty=2)

# plotting with ggplot, need to fix legends
#http://www.cookbook-r.com/Graphs/Legends_(ggplot2)/

qplot(Obs.n,Max.Pred.value,data=gammaData,color=Pop,fill=Pop,geom=c("point","smooth"),method="loess")->bp
bp+scale_fill_discrete(name="Populations",breaks=c("Pop1","Pop2","Pop3","Pop4"),labels=c("Theta=2g", "Theta=2ng","Theta=10g", "Theta=10ng"))
```


# Using theta and number of segregating sites

John's code, starting to dig in this part...

```{r prior info}
# rough estimates from Zakas Q is 10, hapdiv is 0.7
# grabbing a file from Geneious....
library(PopGenome)
file<-readData("FastaSeqs") # actual sample size here is 20. That is the number I'd like to come out...AND, TO AN EXTENT, IT IS AT LEAST IN THE INTERVALS FOR BOTH...
#actual<-20
file@n.sites
basic<-diversity.stats(file)
Hapdiv<-basic@hap.diversity.within #haplotype diversity

Nsite<-basic@n.biallelic.sites #number of seg sites taht are biallelic, for now assume ISM
more<-basic@n.polyallelic.sites
varsite<-Nsite+more

filehaps <- F_ST.stats(file,mode="haplotype",only.haplotype.counts=TRUE)
haplotypecounts <- filehaps@region.stats@haplotype.counts
# this is helpful https://github.com/cran/PopGenome/blob/master/vignettes/Integration_of_new_Methods.Rnw 

########

#install.packages("entropart")
library(entropart)
#need frequencies of haplotypes reported from PopGenome so you can use entropart to get 2D
hapfreq<-unlist(haplotypecounts)
actual<-sum(hapfreq)
hapfreq<-hapfreq/actual
numhaps<-length(hapfreq)

Simp<-expq(Simpson(Ps=hapfreq),q=2)
Gini<-1-(1/Simp)

# Watterson estimator of theta
harm=0
for (n in 1:(actual-1)){
  harm=harm+1/n
}

QW <- varsite/harm

```

```{r WakeleyCh4, echo=FALSE,warning=FALSE,results='hide',message=FALSE,fig.show='asis'}
library(plot3D)

# vector with the sizes we sampled
popsizes<-c(2,4,8,16,32,64,128)

# Now we have the results of segregating sites in 
# pop1segsites
# pop2segsites
# pop3segsites
# pop4segsites

# And we can calculate the max to set our axes
sapply(pop1segsites,function (x) max(x))->maxpop1
max1<-max(maxpop1)
sapply(pop2segsites,function (x) max(x))->maxpop2
max2<-max(maxpop2)
sapply(pop3segsites,function (x) max(x))->maxpop3
max3<-max(maxpop3)
sapply(pop4segsites,function (x) max(x))->maxpop4
max4<-max(maxpop4)

maxn=128
maxk=max(c(max1,max2,max3,max4))

# theta values in our four populations, our "known" value of the "real" population (n=1000 simulated populations in this round)
theta<-c(2,2,10,10)

Q = 2 #theta 

#maxn = min(4*Q,50) #above 70 this behaves funny???? OR IT MAY BE SOME MULTIPLE OF Q*maxn that is problem?

obsvdk = 13
maxk = 2*obsvdk #must be greater than obsvdk

a <- c(1:maxn)
b <- c(1:maxk)
PSKv <- numeric(maxn*maxk)
PSKv <- matrix(PSKv,ncol=maxn)
colnames(PSKv)<-a
rownames(PSKv)<-b

for (n in 2:maxn) {
#  print ("n")
#  print (n)
  for (k in 0:maxk) {
#    print (k)
    PSK=0
    for (i in 2:n) {
#      print (i)
      PSK<-PSK + ((-1)^i)*(choose((n-1),(i-1)))*((i-1)/(Q+i-1))*(Q/(Q+i-1))^k
      
    }
#    print (PSK)
    PSKv[k,n]<-PSKv[k,n]+PSK
    obsvd<-PSKv[obsvdk,]

  }
  
}

hist3D(x=seq(0,1,length.out=nrow(PSKv)),y=seq(0,1,length.out=ncol(PSKv)),PSKv,col=NULL,border="black",theta=30,phi=30,xlab="k",ylab="n",zlab="P{S=k}",alpha=0.35,main=paste((expression(theta))," = ",Q))

#  print(obsvd) #now would be easy to print 95% HPD of obsvd, so for given theta and k this is the distribution of n
  plot(obsvd,xlab="n",ylab="P(n|k)",ylim=c(0,0.15),main=paste("for K =",obsvdk, "and theta =",Q,"in black; for hapdiv in red"))
points(probs[,1],probs[,3],col='red')
abline(v=actual)

```

