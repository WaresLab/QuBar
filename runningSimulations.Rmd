---
title: "Doing Simulations"
author: "Paula Pappalardo"
date: "Wednesday, April 22, 2015"
output: pdf_document
---

# Running simulations

After the first trials, I realized the best method is to call "ms" from R, read that from *gap* and save the file to read it also with *PopGenome*. With *gap* we are able to estimate number of haplotypes. With *PopGenome* we are able to estimate haplotype diversity and also Tajima's D for the cases that we want to simulate "real" populations.

We are going to simulate four populations of 1000 individuals, with the following parameters:

1) theta=2, growth rate to have "good" Tajima's D
2) theta=10, growth rate to have "good" Tajima's D
3) theta=2, no growth
4) theta=10, no growth.

For these four populations we are going to calculate the haplotype diversity and the Tajima's D (to check).

From each of the four populations we are going to sample without replacement "field samples" of 2,4,8,16,32,64 and 128 individuals. That way we know the real n. Using the number of haplotypes and the number of segregating sites of the "field samples" we are going to do our best to back calculate the number of individuals in that sample, using as prior information the haplotype diversity of the original population (n=1000).

The only thing that we need to keep from each "field sample" is the number of haplotypes and number of segregating sites. So to save memory I may try to clean the files we are not using if things get problematic...

NOTE: one thing to have in mind is that we are not controlling for sequence length since there are no sequences in the ms output and we are just seing the segregating sites. That's why the sequence length that is usually visibly with the summary stats in PopGenome is zero when we are reading the ms output file. It shouldn't matter for the things we discussed.

Let's do it! :)

```{r simulating source populations}
library(gap)
library(PopGenome)

# -----gap----
# we can call ms from R without having to use the console and read the object directly with the gap function

# with -G x we set a population growth, a negative value of x means that the population was larger in the past that at present. 

# Simulating our source populations
theta2Growth <- system("ms 1000 1 -t 2 -G 10", intern=TRUE)
theta2NoGrowth <- system("ms 1000 1 -t 2", intern=TRUE)
theta10Growth <- system("ms 1000 1 -t 10 -G 10", intern=TRUE)
theta10NoGrowth <- system("ms 1000 1 -t 10", intern=TRUE)

# we need to write the outputs so we can read them using PopGenome
#write(theta2Growth,"theta2Growth.out")
#write(theta2NoGrowth,"theta2NoGrowth.out")
#write(theta10Growth,"theta10Growth.out")
#write(theta10NoGrowth,"theta10NoGrowth.out")

# reading with PopGenome to calculate H and Tajima's D for each of the four populations
readMS("theta2Growth.out")->popgen.t2g #gives a "genome" object
readMS("theta2NoGrowth.out")->popgen.t2ng
readMS("theta10Growth.out")->popgen.t10g
readMS("theta10NoGrowth.out")->popgen.t10ng

# run F_ST stats and check haplotype diversity
F_ST.stats(popgen.t2g)->popgen.t2g
F_ST.stats(popgen.t2ng)->popgen.t2ng
F_ST.stats(popgen.t10g)->popgen.t10g
F_ST.stats(popgen.t10ng)->popgen.t10ng

# get haplotype diversity for each source population
unlist(popgen.t2g@region.stats@haplotype.diversity)->hapDiv.t2g
unlist(popgen.t2ng@region.stats@haplotype.diversity)->hapDiv.t2ng
unlist(popgen.t10g@region.stats@haplotype.diversity)->hapDiv.t10g
unlist(popgen.t10ng@region.stats@haplotype.diversity)->hapDiv.t10ng

hapDiv<-c(hapDiv.t2g,hapDiv.t2ng,hapDiv.t10g,hapDiv.t10ng)
hapDiv

# run neutrality.stats to check that Tajima's D is negative and looks real
neutrality.stats(popgen.t2g)->popgen.t2g
neutrality.stats(popgen.t2ng)->popgen.t2ng
neutrality.stats(popgen.t10g)->popgen.t10g
neutrality.stats(popgen.t10ng)->popgen.t10ng

Taj.t2g<-popgen.t10g@Tajima.D
Taj.t2ng<-popgen.t10ng@Tajima.D
Taj.t10g<-popgen.t10g@Tajima.D
Taj.t10ng<-popgen.t10ng@Tajima.D

tajima<-c(Taj.t2g,Taj.t2ng,Taj.t10g,Taj.t10ng)
tajima
```

Now that we have our 4 populations and we have H and Tajima's D for those, we need to take our "field samples". For that, we are going to use the same pop generated above and read those with gap. Then, using the matrix of the variables sites for the 1000 individuals we are going to take random samples. We are going to use sample sizes from 2 to 128 in a log2 scale.

# Taking "field samples"

```{r taking field samples}
library(gap)
library(PopGenome)

# reading the ms output generated in the previous chunk with gap
# this way works for reading the object from R, but it is not useful if we want to maintain the origina same populations, because I was not able to make the "seeds" work
#read.ms.output(theta2Growth,FALSE)->pop1
#read.ms.output(theta2NoGrowth,FALSE)->pop2
#read.ms.output(theta10Growth,FALSE)->pop3
#read.ms.output(theta10NoGrowth,FALSE)->pop4

# this way, we read the same files that were simulated only once, and the same that we read with PopGenome
read.ms.output("theta2Growth.out",is.file=T)->pop1
read.ms.output("theta2NoGrowth.out",is.file=T)->pop2
read.ms.output("theta10Growth.out",is.file=T)->pop3
read.ms.output("theta10NoGrowth.out",is.file=T)->pop4

# --------sampling from each population---------
# vector with all the populations for loops or easy coding
pop<-list(pop1,pop2,pop3,pop4)

# vector with the sizes we want to sample
popsizes<-c(2,4,8,16,32,64,128)

# we extract the gametes matrix for each population, from there we take the samples, we put the matrix obtained in each "sample" in a list called "samples", and the result for each population in a list called "populations"

populations<-list() #empty list to put results
set.seed(123) #set seed for random sampling

# loop in each population to take the field samples, 100 replicates for each sampling size
for(i in 1:length(pop)){
  pop[[i]]->ourpop #pick a population
  namepop<-paste("popOrigen",i,sep="")
  t(ourpop$gametes[[1]])->mat #transpose matrix to have individuals as rows
  samples<-list() #empty list to put the sampling of each sample size
    for(j in popsizes){
        name<-paste("sampleSize",j,sep="")
        replicates<-list() #empty list to put each replicate (n=100)
        for (k in 1:100){
        namerep<-paste("replicate",k,sep="")  
        mat[sample(nrow(mat),size=j,replace=FALSE),]->rep
        rep->replicates[[namerep]]
        }
        replicates->samples[[name]]
      }
  samples->populations[[namepop]]
} # now in each of the 4 components of the list "populations", we have 7 list with each component corresponding to each sample size, and within each of this list we have 100 components corresponding to each replicate of the sampled matrix.
```

The object **populations** has 4 components (one for each population), each one include 7 lists (one for each sampling size), and within each of the sampling sizes we have a list with the 100 matrix sampled.
Now we are going to calculate number of  haplotypes and number of segregating sites for each of the replicates in each of the samples in each of the 4 populations. The loops takes a while to be able to do it for all the replicates.

```{r calculating haplotypes}
# Now for each sample we need to calculate the segregating sites and number of haplotypes
# the haplotype number can be extracted by doing unique() of the matrix
hapResults<-list()
for(i in 1:length(pop)){
  populations[[i]]->popnow
  namepop<-paste("popOrigen",i,sep="")
  samples<-list()
  for (j in 1:length(popsizes)){
    namesample<-paste("sampleSize",j,sep="")  
    popnow[[j]]->samplenow
    for (k in 1:100){
      sapply(samplenow,function(x) nrow(unique(x)))->result
      unlist(result)->replicates
      }
    replicates->samples[[namesample]]
    }
  samples->hapResults[[namepop]]
} # now hapResults is a list of vectors with the haplotypes number for each population, in each sample size
hapResults[[1]]->pop1haps
hapResults[[2]]->pop2haps
hapResults[[3]]->pop3haps
hapResults[[4]]->pop4haps
```
We are going to do a similar procedure to estimate the number of segregating sites. We first created a function to estimate the number of segregating sites from the gametes matrix provided by the MS simulation. And the we apply that looping over our samples.

```{r calculating segregating sites}
# load function to estimate segregating sites, it works taking a matrix of gametes and returning a numeric value, the number of segregating sites.
estimate.segSites <- function(myMatrix){
  answers<-rep(NA,(nrow(myMatrix)-1))
  sites<-rep(NA,ncol(myMatrix))
    for (j in 1:ncol(myMatrix)){
      for (i in 1:(nrow(myMatrix)-1)){
        (myMatrix[i+1,j]==myMatrix[1,j])->answers[i]
      }
      if (all(answers)==TRUE) {0->sites[j]}
      else {1->sites[j]}
      }
    sum(sites,na.rm=T)->segSites
    return(segSites)
  }

# to get segsites for each population we need to use our custome function in a loop
segResults<-list()
for(i in 1:length(pop)){
  populations[[i]]->popnow
  namepop<-paste("popOrigen",i,sep="")
  samples<-list()
  for (j in 1:length(popsizes)){
    namesample<-paste("sampleSize",j,sep="")
    popnow[[j]]->samplenow
    sapply(samplenow,function(x) estimate.segSites(x))->result
    result->samples[[namesample]]
    }
  samples->segResults[[namepop]]
}  # now segResults is a list of 4 lists (one for each population), within each of those list compose of a list of 7 vectors, one for each sample size, and with a length of 100, where each component is the segregating sites for the 100 replicates. 
segResults
segResults[[1]]->pop1segsites
segResults[[2]]->pop2segsites
segResults[[3]]->pop3segsites
segResults[[4]]->pop4segsites
```

Since these calculations take quite a while (at least the haplotypes), we are going to save our results in a dataframe, the number of haplotypes and the number of segreating sites for each population. The following chunk may not be very efficient but it works fine.

```{r making dataframe with haplotypes and segSites}
# probably not efficient at all, but it works
# number of haplotypes----
Population<-rep(NA,700)
Haplotypes<-rep(NA,700)
data.frame(Population,Haplotypes)->toFillhap
toFillhap->toFillhap2
toFillhap->toFillhap3
toFillhap->toFillhap4

count<-0
for (j in 1:7){
  pop1haps[[j]]->oursize
  names(oursize)<-NULL
  for (i in 1:100){
  toFillhap$Haplotypes[i+count]<-oursize[i]
  toFillhap$Population[i+count]<-"Pop1"
  }
  count+100->count
 }
count<-0
for (j in 1:7){
  pop2haps[[j]]->oursize
  names(oursize)<-NULL
  for (i in 1:100){
  toFillhap2$Haplotypes[i+count]<-oursize[i]
  toFillhap2$Population[i+count]<-"Pop2"
  }
  count+100->count
 }
count<-0
for (j in 1:7){
  pop3haps[[j]]->oursize
  names(oursize)<-NULL
  for (i in 1:100){
  toFillhap3$Haplotypes[i+count]<-oursize[i]
  toFillhap3$Population[i+count]<-"Pop3"
  }
  count+100->count
 }
count<-0
for (j in 1:7){
  pop4haps[[j]]->oursize
  names(oursize)<-NULL
  for (i in 1:100){
  toFillhap4$Haplotypes[i+count]<-oursize[i]
  toFillhap4$Population[i+count]<-"Pop4"
  }
  count+100->count
 }

# putting populations together
rbind(toFillhap,toFillhap2,toFillhap3,toFillhap4)->hapData

# number of segregating sites----
Population<-rep(NA,700)
segSites<-rep(NA,700)
data.frame(Population,segSites)->toFillseg
toFillseg->toFillseg2
toFillseg->toFillseg3
toFillseg->toFillseg4

count<-0
for (j in 1:7){
  pop1segsites[[j]]->oursize
  names(oursize)<-NULL
  for (i in 1:100){
  toFillseg$segSites[i+count]<-oursize[i]
  toFillseg$Population[i+count]<-"Pop1"
  }
  count+100->count
 }
count<-0
for (j in 1:7){
  pop2segsites[[j]]->oursize
  names(oursize)<-NULL
  for (i in 1:100){
  toFillseg2$segSites[i+count]<-oursize[i]
  toFillseg2$Population[i+count]<-"Pop2"
  }
  count+100->count
 }
count<-0
for (j in 1:7){
  pop3segsites[[j]]->oursize
  names(oursize)<-NULL
  for (i in 1:100){
  toFillseg3$segSites[i+count]<-oursize[i]
  toFillseg3$Population[i+count]<-"Pop3"
  }
  count+100->count
 }
count<-0
for (j in 1:7){
  pop4segsites[[j]]->oursize
  names(oursize)<-NULL
  for (i in 1:100){
  toFillseg4$segSites[i+count]<-oursize[i]
  toFillseg4$Population[i+count]<-"Pop4"
  }
  count+100->count
 }

# putting things together----
rbind(toFillseg,toFillseg2,toFillseg3,toFillseg4)->segData
c(rep(2,100),rep(4,100),rep(8,100),rep(16,100),rep(32,100),rep(64,100),rep(128,100))->sampleSize
cbind(hapData,segData$segSites,rep(sampleSize,4))->hapsegData
names(hapsegData)<-c("Populations","Haplotypes","segSites","sampleSize")
# save result so we don't need to rerun----
write.csv(hapsegData,"hapsegData.csv")
```

Now we have the dataframe "hapsegData" with the number of haplotypes and segregating sites for each replicate, for each population, and we don't need to run the chunk everytime.

# Using the gamma approach

Now we have 100 replicates of each sample size, for each population, and we want to run the gamma stats for each replicate in each sampling size. To save the results I created a dataframe "toFill", and since the haplotype calculation takes its time, I will save that dataframe so we don't have to calculate the haplotypes each time.

```{r gamma distribution code,eval=F}
# load libraries
library(lattice)
library(ggplot2)
library(vioplot)

# Number of samples, from a log2 distribution, it is the same for all populations
numsamp<-c(2,4,8,16,32,64,128) 

# Haplotype diversity for each of the four simulated populations of 1000 individuals
hapdiv<-c(0.5504204, 0.3377538, 0.8915536, 0.9258679)

# Number of haplotypes for each replicates are in a list within a list
# pop1haps (list of 7 sampling sizes, that includes the list with 100 replicates)
# pop2haps
# pop3haps
# pop4haps

# We can make this more efficient, but for now, let's keep a loop for each population:

# set dataframe to fill with the predicted and observed values,for each population, we need 
Population<-rep(NA,700)
Max.Pred.value<-rep(NA,700)
data.frame(Population,Max.Pred.value)->toFill
toFill->toFill2
toFill->toFill3
toFill->toFill4

# Loop in all populations to get the estimates----

# Loop population 1
count<-0
for (j in 1:7){
  pop1haps[[j]]->ourSize
  names(ourSize)<-NULL
    for(i in 1:100){
      x=1
      cdf=0
      indprob=0
      array<-NULL
    while (cdf<0.99) {
      cdfprev<-cdf
      cdf<-pgamma(x,ourSize[i],hapdiv[1]) 
      indprob<-cdf-cdfprev
      happrob<-ourSize[i]+(x-1)
      array<-c(array,happrob)
      array<-c(array,cdf)
      array<-c(array,indprob)
      x=x+1
      }
  probs<-t(matrix(array,nrow=3))
  probs
  max<-max(probs[,3])
  maxPred<-probs[which(probs[,3]==max),1]
  toFill$Max.Pred.value[i+count]<-maxPred
  toFill$Obs.n[i+count]<-numsamp[j]
  toFill$Population[i+count]<-"Pop1"
  }
  count+100->count
 }

# Loop population 2
count<-0
for (j in 1:7){
  pop2haps[[j]]->ourSize
  names(ourSize)<-NULL
    for(i in 1:100){
      x=1
      cdf=0
      indprob=0
      array<-NULL
    while (cdf<0.99) {
      cdfprev<-cdf
      cdf<-pgamma(x,ourSize[i],hapdiv[1]) 
      indprob<-cdf-cdfprev
      happrob<-ourSize[i]+(x-1)
      array<-c(array,happrob)
      array<-c(array,cdf)
      array<-c(array,indprob)
      x=x+1
      }
  probs<-t(matrix(array,nrow=3))
  probs
  max<-max(probs[,3])
  maxPred<-probs[which(probs[,3]==max),1]
  toFill2$Max.Pred.value[i+count]<-maxPred
  toFill2$Obs.n[i+count]<-numsamp[j]
  toFill2$Population[i+count]<-"Pop2"
  }
  count+100->count
 }

# Loop population 3
count<-0
for (j in 1:7){
  pop3haps[[j]]->ourSize
  names(ourSize)<-NULL
    for(i in 1:100){
      x=1
      cdf=0
      indprob=0
      array<-NULL
    while (cdf<0.99) {
      cdfprev<-cdf
      cdf<-pgamma(x,ourSize[i],hapdiv[1]) 
      indprob<-cdf-cdfprev
      happrob<-ourSize[i]+(x-1)
      array<-c(array,happrob)
      array<-c(array,cdf)
      array<-c(array,indprob)
      x=x+1
      }
  probs<-t(matrix(array,nrow=3))
  probs
  max<-max(probs[,3])
  maxPred<-probs[which(probs[,3]==max),1]
  toFill3$Max.Pred.value[i+count]<-maxPred
  toFill3$Obs.n[i+count]<-numsamp[j]
  toFill3$Population[i+count]<-"Pop3"
  }
  count+100->count
 }

# Loop population 4
count<-0
for (j in 1:7){
  pop4haps[[j]]->ourSize
  names(ourSize)<-NULL
    for(i in 1:100){
      x=1
      cdf=0
      indprob=0
      array<-NULL
    while (cdf<0.99) {
      cdfprev<-cdf
      cdf<-pgamma(x,ourSize[i],hapdiv[1]) 
      indprob<-cdf-cdfprev
      happrob<-ourSize[i]+(x-1)
      array<-c(array,happrob)
      array<-c(array,cdf)
      array<-c(array,indprob)
      x=x+1
      }
  probs<-t(matrix(array,nrow=3))
  probs
  max<-max(probs[,3])
  maxPred<-probs[which(probs[,3]==max),1]
  toFill4$Max.Pred.value[i+count]<-maxPred
  toFill4$Obs.n[i+count]<-numsamp[j]
  toFill4$Population[i+count]<-"Pop4"
  }
  count+100->count
 }

# putting populations together
rbind(toFill,toFill2,toFill3,toFill4)->gammaData

# With this I can do a summary table of the frequency of predicted haplotypes for each observed value
table(toFill$Pred.value,toFill$Obs.n)

# save result so we don't need to rerun----
write.csv(gammaData,"gammaData.csv")
```

```{r gamma distribution plot}
library(lattice)
library(ggplot2)
library(vioplot)

# now we have the dataframe "gammaData" with all the values we need to plot
gammaData<-read.csv("gammaData.csv",header=T)
table(gammaData$Population,gammaData$Obs.n)


par(mfrow=c(1,1))
plot(Pred.value~Obs.n,data=toFill)
vioplot(toFill$Pred.value,add=T,horizontal=F,lty=2)

# plotting with ggplot, need to fix legends
#http://www.cookbook-r.com/Graphs/Legends_(ggplot2)/

qplot(Obs.n,Max.Pred.value,data=gammaData,color=Pop,fill=Pop,geom=c("point","smooth"),method="loess")->bp
bp+scale_fill_discrete(name="Populations",breaks=c("Pop1","Pop2","Pop3","Pop4"),labels=c("Theta=2g", "Theta=2ng","Theta=10g", "Theta=10ng"))
```

```{r gamma summarizing plots}
library(lattice)

# load data with observed haplotypesin the samples
data<-read.csv("hapsegData.csv",header=T)
factor(data$sampleSize)->data$sampleSizeF
data<-data[with(data,order(Haplotypes)),]
databp<-data[with(data,order(Populations)),]

# plotting multiples boxplot with lattice
with(data,bwplot(Haplotypes~sampleSizeF|Populations,layout=c(2,2)))

pop1<-data[which(data$Populations=='Pop1'),]
pop2<-data[which(data$Populations=='Pop2'),]
pop3<-data[which(data$Populations=='Pop3'),]
pop4<-data[which(data$Populations=='Pop4'),]

# to plot multiples histogram with lattice
with(pop2,histogram(~Haplotypes|sampleSizeF,layout=c(2,4)))

plot(data$Haplotypes,col=data$sampleSize)
plot(data$Haplotypes,col=data$Population)
```



# Using theta and number of segregating sites

John's code, starting to dig in this part...

```{r prior info}
# rough estimates from Zakas Q is 10, hapdiv is 0.7
# grabbing a file from Geneious....
library(PopGenome)
file<-readData("FastaSeqs") # actual sample size here is 20. That is the number I'd like to come out...AND, TO AN EXTENT, IT IS AT LEAST IN THE INTERVALS FOR BOTH...
#actual<-20
file@n.sites
basic<-diversity.stats(file)
Hapdiv<-basic@hap.diversity.within #haplotype diversity

Nsite<-basic@n.biallelic.sites #number of seg sites taht are biallelic, for now assume ISM
more<-basic@n.polyallelic.sites
varsite<-Nsite+more

filehaps <- F_ST.stats(file,mode="haplotype",only.haplotype.counts=TRUE)
haplotypecounts <- filehaps@region.stats@haplotype.counts
# this is helpful https://github.com/cran/PopGenome/blob/master/vignettes/Integration_of_new_Methods.Rnw 

########

#install.packages("entropart")
library(entropart)
#need frequencies of haplotypes reported from PopGenome so you can use entropart to get 2D
hapfreq<-unlist(haplotypecounts)
actual<-sum(hapfreq)
hapfreq<-hapfreq/actual
numhaps<-length(hapfreq)

Simp<-expq(Simpson(Ps=hapfreq),q=2)
Gini<-1-(1/Simp)

# Watterson estimator of theta
harm=0
for (n in 1:(actual-1)){
  harm=harm+1/n
}

QW <- varsite/harm

```

```{r WakeleyCh4, echo=FALSE,warning=FALSE,results='hide',message=FALSE,fig.show='asis'}
library(plot3D)

# load data with observed segregating sites in the samples
data<-read.csv("hapsegData.csv",header=T)

# getting the unique combinations of segregating sites per population/theta to enter in the Wakeley formula
segdata<-unique(data[,c("Populations","segSites","sampleSize")])

# taking out the values of zero segregating sites
zero<-which(segdata$segSites==0)
segdata[-zero,]->segdata

# we need to define a maximum n, John identified that above 70 this behaves funny 
maxn=60
maxk<-max(segdata$segSites)

# theta values in our four populations, our "known" value of the "real" population (n=1000 simulated populations in this round)
theta<-c(2,2,10,10)

# -----theta=2-----------
Q = 2 #theta 
segdata2<-subset(segdata,Populations=="Pop1"|Populations=="Pop2")

# creating empty list to put the results
ndistT2<-list()

# looping in segdata and running Wakeley formula
for (z in 1:nrow(segdata2)){
  name<-paste("seg",z,sep="")
  obsvdk<-segdata2$segSites[z]
  a <- c(1:maxn)
  b <- c(1:maxk)
  PSKv <- numeric(maxn*maxk)
  PSKv <- matrix(PSKv,ncol=maxn)
  colnames(PSKv)<-a
  rownames(PSKv)<-b
  
  for (n in 2:maxn) {
        PSK=0
        for (i in 2:n) {
             PSK<-PSK + ((-1)^i)*(choose((n-1),(i-1)))*((i-1)/(Q+i-1))*(Q/(Q+i-1))^obsvdk
        }
        PSKv[obsvdk,n]<-PSKv[obsvdk,n]+PSK
      obsvd<-PSKv[obsvdk,]
      obsvd->ndistT2[[name]]
      }
    }
  
# The result of the loop is a list "ndistT2", with each component being one observed segregating site value, and within that a vector with length maxn, and components theh probability values for that segsite according to Wakeley.

# -----theta=10-----------
Q = 10 #theta 
segdata10<-subset(segdata,Populations=="Pop3"|Populations=="Pop4")

# creating empty list to put the results
ndistT10<-list()

# looping in segdata and running Wakeley formula
for (z in 1:nrow(segdata10)){
  name<-paste("seg",z,sep="")
  obsvdk<-segdata2$segSites[z]
  a <- c(1:maxn)
  b <- c(1:maxk)
  PSKv <- numeric(maxn*maxk)
  PSKv <- matrix(PSKv,ncol=maxn)
  colnames(PSKv)<-a
  rownames(PSKv)<-b
  
  for (n in 2:maxn) {
        PSK=0
        for (i in 2:n) {
             PSK<-PSK + ((-1)^i)*(choose((n-1),(i-1)))*((i-1)/(Q+i-1))*(Q/(Q+i-1))^obsvdk
        }
        PSKv[obsvdk,n]<-PSKv[obsvdk,n]+PSK
      obsvd<-PSKv[obsvdk,]
      obsvd->ndistT10[[name]]
      }
    }
  
# The result of the loop is a list "ndistT10", with each component being one observed segregating site value, and within that a vector with length maxn, and components theh probability values for that segsite according to Wakeley.






hist3D(x=seq(0,1,length.out=nrow(PSKv)),y=seq(0,1,length.out=ncol(PSKv)),PSKv,col=NULL,border="black",theta=30,phi=30,xlab="k",ylab="n",zlab="P{S=k}",alpha=0.35,main=paste((expression(theta))," = ",Q))

#  print(obsvd) #now would be easy to print 95% HPD of obsvd, so for given theta and k this is the distribution of n
  plot(obsvd,xlab="n",ylab="P(n|k)",ylim=c(0,0.15),main=paste("for K =",obsvdk, "and theta =",Q,"in black; for hapdiv in red"))
points(probs[,1],probs[,3],col='red')
abline(v=actual)

```

